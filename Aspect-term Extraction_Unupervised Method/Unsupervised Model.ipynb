{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1298b96",
   "metadata": {},
   "source": [
    "# Reading data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc340bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe4fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    \"\"\"\n",
    "    desc:\n",
    "    ====\n",
    "    Takes in the filename, outputs a list of dictionaries. The dictionary will contain\n",
    "    [review_id, raw_text, aspect_term, aspect_polarity]\n",
    "    \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    processed_data = [] # Store the final list of dictionaries\n",
    "    \n",
    "    for sentence in root.findall('sentence'):\n",
    "        data = {}\n",
    "        raw_text = sentence[0].text\n",
    "        aspects = []\n",
    "        aspect_polarity = []\n",
    "        sentence_id = sentence.attrib['id']\n",
    "        all_terms = sentence.find('aspectTerms')\n",
    "        \n",
    "        if all_terms: # If there are aspect terms\n",
    "            all_terms_lst = all_terms.findall('aspectTerm')\n",
    "            for ele in all_terms_lst: # Iterate through all aspect terms in senetence\n",
    "                term = ele.get('term')\n",
    "                aspects.append(term)\n",
    "                term_polarity = ele.get('polarity')\n",
    "                aspect_polarity.append(term_polarity)\n",
    "        data['review_id'] = sentence_id\n",
    "        data['raw_text'] = raw_text\n",
    "        data['aspect_term'] = aspects\n",
    "        data['aspect_polarity'] = aspect_polarity\n",
    "        \n",
    "        processed_data.append(data)\n",
    "    return processed_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1940b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = preprocess('Restaurants_Train.xml')\n",
    "train = pd.DataFrame(train_raw)\n",
    "test_raw = preprocess('Restaurants_Test.xml')\n",
    "test = pd.DataFrame(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3adba15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from string import punctuation\n",
    "\n",
    "\n",
    "# def pos_tag(texts):\n",
    "#     text_tags = []\n",
    "#     processed_text = []\n",
    "#     for text in texts:\n",
    "#         text = text.lower()\n",
    "#         text = nltk.word_tokenize(text)\n",
    "#         text = [word for word in text if word not in punctuation]\n",
    "#         tag_words = nltk.pos_tag(text)\n",
    "#         tags = []\n",
    "#         sent = []\n",
    "#         for i in tag_words:\n",
    "#             if i[1] not in punctuation:\n",
    "#                 tags.append(i[1])\n",
    "#             if i[0] not in punctuation:\n",
    "#                 sent.append(i[0])\n",
    "#         text_tags.append(tags)\n",
    "#         processed_text.append(sent)\n",
    "#     return text_tags,processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36676e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_tags, processed_text = pos_tag(train['raw_text'])\n",
    "# df = pd.DataFrame()\n",
    "# joined_text = []\n",
    "# for lst in processed_text:\n",
    "#     joined_text.append(' '.join(lst))\n",
    "# df['text_full'] = joined_text\n",
    "# df['text'] = processed_text\n",
    "# df['pos_tags'] = text_tags\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e67e3c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 20:45:07 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-04-02 20:45:07 INFO: Use device: gpu\n",
      "2022-04-02 20:45:07 INFO: Loading: tokenize\n",
      "2022-04-02 20:45:10 INFO: Loading: pos\n",
      "2022-04-02 20:45:10 INFO: Loading: lemma\n",
      "2022-04-02 20:45:10 INFO: Loading: depparse\n",
      "2022-04-02 20:45:10 INFO: Loading: sentiment\n",
      "2022-04-02 20:45:11 INFO: Loading: constituency\n",
      "2022-04-02 20:45:11 INFO: Loading: ner\n",
      "2022-04-02 20:45:11 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline('en', use_gpu = True)\n",
    "# doc = nlp(list(df['text_full']))\n",
    "def get_dependencies(pipeline,data):\n",
    "    word_lst = []\n",
    "    pos_tag = []\n",
    "    all_tags = []\n",
    "    word_joined = []\n",
    "    for j in data:\n",
    "        ind_tag = []\n",
    "        temp_word = []\n",
    "        temp_pos = []\n",
    "        en_doc = pipeline(j)\n",
    "        for i,sent in enumerate(en_doc.sentences):\n",
    "            for word in sent.words:\n",
    "                ind_tag.append((word.head,word.deprel))\n",
    "                temp_word.append(word.text)\n",
    "                temp_pos.append(word.xpos)\n",
    "        all_tags.append(ind_tag)\n",
    "        word_lst.append(temp_word)\n",
    "        pos_tag.append(temp_pos)\n",
    "        word_joined.append(' '.join(temp_word))\n",
    "    df = pd.DataFrame()\n",
    "    df['text_full'] = word_joined\n",
    "    df['text'] = word_lst\n",
    "    df['pos_tags'] = pos_tag\n",
    "    df['dependencies'] = all_tags\n",
    "    return df\n",
    "df = get_dependencies(nlp,train['raw_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e3e5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_full</th>\n",
       "      <th>text</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>dependencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the staff was so horrible to us .</td>\n",
       "      <td>[But, the, staff, was, so, horrible, to, us, .]</td>\n",
       "      <td>[CC, DT, NN, VBD, RB, JJ, IN, PRP, .]</td>\n",
       "      <td>[(6, cc), (3, det), (6, nsubj), (6, cop), (6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To be completely fair , the only redeeming fac...</td>\n",
       "      <td>[To, be, completely, fair, ,, the, only, redee...</td>\n",
       "      <td>[TO, VB, RB, JJ, ,, DT, JJ, JJ, NN, VBD, DT, N...</td>\n",
       "      <td>[(4, mark), (4, cop), (4, advmod), (12, advcl)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food is uniformly exceptional , with a ver...</td>\n",
       "      <td>[The, food, is, uniformly, exceptional, ,, wit...</td>\n",
       "      <td>[DT, NN, VBZ, RB, JJ, ,, IN, DT, RB, JJ, NN, W...</td>\n",
       "      <td>[(2, det), (5, nsubj), (5, cop), (5, advmod), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>[Where, Gabriela, personaly, greets, you, and,...</td>\n",
       "      <td>[WRB, NNP, RB, VBZ, PRP, CC, VBZ, PRP, WP, TO,...</td>\n",
       "      <td>[(4, advmod), (4, nsubj), (4, advmod), (0, roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For those that go once and do n't enjoy it , a...</td>\n",
       "      <td>[For, those, that, go, once, and, do, n't, enj...</td>\n",
       "      <td>[IN, DT, WDT, VBP, RB, CC, VBP, RB, VB, PRP, ,...</td>\n",
       "      <td>[(2, case), (16, obl), (4, nsubj), (2, acl:rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>But that is highly forgivable .</td>\n",
       "      <td>[But, that, is, highly, forgivable, .]</td>\n",
       "      <td>[CC, DT, VBZ, RB, JJ, .]</td>\n",
       "      <td>[(5, cc), (5, nsubj), (5, cop), (5, advmod), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>From the appetizers we ate , the dim sum and o...</td>\n",
       "      <td>[From, the, appetizers, we, ate, ,, the, dim, ...</td>\n",
       "      <td>[IN, DT, NNS, PRP, VBD, ,, DT, JJ, NN, CC, JJ,...</td>\n",
       "      <td>[(3, case), (3, det), (18, obl), (5, nsubj), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>When we arrived at 6:00 PM , the restaurant wa...</td>\n",
       "      <td>[When, we, arrived, at, 6:00, PM, ,, the, rest...</td>\n",
       "      <td>[WRB, PRP, VBD, IN, CD, NN, ,, DT, NN, VBD, RB...</td>\n",
       "      <td>[(3, mark), (3, nsubj), (12, advcl), (6, case)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>[Each, table, has, a, pot, of, boiling, water,...</td>\n",
       "      <td>[DT, NN, VBZ, DT, NN, IN, VBG, NN, JJ, IN, PRP...</td>\n",
       "      <td>[(2, det), (3, nsubj), (0, root), (5, det), (3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>I am going to the mid town location next .</td>\n",
       "      <td>[I, am, going, to, the, mid, town, location, n...</td>\n",
       "      <td>[PRP, VBP, VBG, IN, DT, JJ, NN, NN, RB, .]</td>\n",
       "      <td>[(3, nsubj), (3, aux), (0, root), (8, case), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3041 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_full  \\\n",
       "0                 But the staff was so horrible to us .   \n",
       "1     To be completely fair , the only redeeming fac...   \n",
       "2     The food is uniformly exceptional , with a ver...   \n",
       "3     Where Gabriela personaly greets you and recomm...   \n",
       "4     For those that go once and do n't enjoy it , a...   \n",
       "...                                                 ...   \n",
       "3036                    But that is highly forgivable .   \n",
       "3037  From the appetizers we ate , the dim sum and o...   \n",
       "3038  When we arrived at 6:00 PM , the restaurant wa...   \n",
       "3039  Each table has a pot of boiling water sunken i...   \n",
       "3040         I am going to the mid town location next .   \n",
       "\n",
       "                                                   text  \\\n",
       "0       [But, the, staff, was, so, horrible, to, us, .]   \n",
       "1     [To, be, completely, fair, ,, the, only, redee...   \n",
       "2     [The, food, is, uniformly, exceptional, ,, wit...   \n",
       "3     [Where, Gabriela, personaly, greets, you, and,...   \n",
       "4     [For, those, that, go, once, and, do, n't, enj...   \n",
       "...                                                 ...   \n",
       "3036             [But, that, is, highly, forgivable, .]   \n",
       "3037  [From, the, appetizers, we, ate, ,, the, dim, ...   \n",
       "3038  [When, we, arrived, at, 6:00, PM, ,, the, rest...   \n",
       "3039  [Each, table, has, a, pot, of, boiling, water,...   \n",
       "3040  [I, am, going, to, the, mid, town, location, n...   \n",
       "\n",
       "                                               pos_tags  \\\n",
       "0                 [CC, DT, NN, VBD, RB, JJ, IN, PRP, .]   \n",
       "1     [TO, VB, RB, JJ, ,, DT, JJ, JJ, NN, VBD, DT, N...   \n",
       "2     [DT, NN, VBZ, RB, JJ, ,, IN, DT, RB, JJ, NN, W...   \n",
       "3     [WRB, NNP, RB, VBZ, PRP, CC, VBZ, PRP, WP, TO,...   \n",
       "4     [IN, DT, WDT, VBP, RB, CC, VBP, RB, VB, PRP, ,...   \n",
       "...                                                 ...   \n",
       "3036                           [CC, DT, VBZ, RB, JJ, .]   \n",
       "3037  [IN, DT, NNS, PRP, VBD, ,, DT, JJ, NN, CC, JJ,...   \n",
       "3038  [WRB, PRP, VBD, IN, CD, NN, ,, DT, NN, VBD, RB...   \n",
       "3039  [DT, NN, VBZ, DT, NN, IN, VBG, NN, JJ, IN, PRP...   \n",
       "3040         [PRP, VBP, VBG, IN, DT, JJ, NN, NN, RB, .]   \n",
       "\n",
       "                                           dependencies  \n",
       "0     [(6, cc), (3, det), (6, nsubj), (6, cop), (6, ...  \n",
       "1     [(4, mark), (4, cop), (4, advmod), (12, advcl)...  \n",
       "2     [(2, det), (5, nsubj), (5, cop), (5, advmod), ...  \n",
       "3     [(4, advmod), (4, nsubj), (4, advmod), (0, roo...  \n",
       "4     [(2, case), (16, obl), (4, nsubj), (2, acl:rel...  \n",
       "...                                                 ...  \n",
       "3036  [(5, cc), (5, nsubj), (5, cop), (5, advmod), (...  \n",
       "3037  [(3, case), (3, det), (18, obl), (5, nsubj), (...  \n",
       "3038  [(3, mark), (3, nsubj), (12, advcl), (6, case)...  \n",
       "3039  [(2, det), (3, nsubj), (0, root), (5, det), (3...  \n",
       "3040  [(3, nsubj), (3, aux), (0, root), (8, case), (...  \n",
       "\n",
       "[3041 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d44522",
   "metadata": {},
   "source": [
    "# Rule-Based Aspect Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ec62b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced', '2-faces', 'abnormal', 'abolish', ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bing Liu sentiment lexicon\n",
    "from nltk.corpus import opinion_lexicon\n",
    "opinion_words = opinion_lexicon.words()\n",
    "opinion_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fabdaa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspects1(data, op_lex):\n",
    "    \"\"\"\n",
    "    desc: rule based aspect extraction\n",
    "    ====\n",
    "    Inputs: processed data, bingliu sentiment lexicons\n",
    "    Outputs: 2-d array where each nested array\n",
    "    \"\"\"\n",
    "    aspects = []\n",
    "    best_aspects = []\n",
    "    ## level 1\n",
    "    for ind, row in data.iterrows():\n",
    "        if ind%200 == 0:\n",
    "            print(ind)\n",
    "        temp_aspects = []\n",
    "        temp_best_aspects = []\n",
    "        word_lst = row.text\n",
    "        pos_tags = row.pos_tags\n",
    "        dependencies = row.dependencies\n",
    "        for i in range(len(word_lst)):\n",
    "            # (adj noun), adjective is not opinion, concat and add to aspect\n",
    "            if pos_tags[i] in ['NN'] and i>0 and pos_tags[i-1] in ['JJ'] and word_lst[i-1].lower() not in op_lex:\n",
    "                concat_word = ' '.join(word_lst[i-1:i+1])\n",
    "                if concat_word not in temp_aspects:\n",
    "                    temp_aspects.append(concat_word)\n",
    "                    \n",
    "            # (noun noun) concat and add to aspect\n",
    "            if pos_tags[i] in ['NN'] and i>0 and pos_tags[i-1] in ['NN']:\n",
    "                concat_word = ' '.join(word_lst[i-1:i+1])\n",
    "                if concat_word not in temp_aspects:\n",
    "                    temp_aspects.append(concat_word)\n",
    "                    \n",
    "            # (adj noun), adjective is opinion, add noun to aspect\n",
    "            if pos_tags[i] in ['NN','NNS'] and i>0 and pos_tags[i-1] in ['JJ'] and word_lst[i-1].lower() in op_lex:\n",
    "                if word_lst[i] not in temp_aspects:\n",
    "                    temp_aspects.append(word_lst[i])\n",
    "                if word_lst[i] not in temp_best_aspects:\n",
    "                    temp_best_aspects.append(word_lst[i])\n",
    "                    \n",
    "                    \n",
    "\n",
    "            # noun, dobj releationship with verb\n",
    "            if pos_tags[i] in ['NN','NNS'] and dependencies[i][1] == 'dobj' and pos_tags[dependencies[i][0]-1] in ['VB','VBN']:\n",
    "                if word_lst[i] not in temp_aspects:\n",
    "                    temp_aspects.append(word_lst[i])\n",
    "                    \n",
    "            # noun, nsubj releationship with adjective\n",
    "            if pos_tags[i] in ['NN','NNS'] and dependencies[i][1] == 'nsubj' and pos_tags[dependencies[i][0]-1] in ['JJ']:\n",
    "                if word_lst[i] not in temp_aspects:\n",
    "                    temp_aspects.append(word_lst[i])\n",
    "            \n",
    "#             noun, relationship with copula verb\n",
    "#             if pos_tags[i] in ['NN'] and dependencies[i][1] == 'cop' and pos_tags[dependencies[i][0]-1] in ['VB','VBD','VBP']:\n",
    "#                 if word_lst[i] not in temp_aspects:\n",
    "#                     temp_aspects.append(word_lst[i])\n",
    "#                 if word_lst[i] not in temp_best_aspects:\n",
    "#                     temp_best_aspects.append(word_lst[i])\n",
    "                    \n",
    "#             sentence contains subject verb and word has an advmod or amod which is an opinion word\n",
    "#             for j in range(len(pos_tags)-1):\n",
    "#                 temp_tag = pos_tags[j:j+2]\n",
    "#                 if temp_tag[0] in ['PRP','PRP$'] and temp_tag[1] in ['VB','VBD','VBG','VBN']:\n",
    "#                     if pos_tags[i] in ['NN'] and dependencies[i][1] in ['amod','advmod'] and word_lst[dependencies[i][0]-1] in op_lex:\n",
    "#                         if word_lst[i] not in temp_aspects:\n",
    "#                             temp_aspects.append(word_lst[i])\n",
    "#                         if word_lst[i] not in temp_best_aspects:\n",
    "#                             temp_best_aspects.append(word_lst[i])\n",
    "            \n",
    "        aspects.append(temp_aspects)\n",
    "        best_aspects.append(temp_best_aspects)\n",
    "    return aspects, best_aspects\n",
    "    ## level 2\n",
    "def extract_aspects2(data, aspects):\n",
    "    aspects_level2 = copy.deepcopy(aspects)\n",
    "    for ind, row in data.iterrows():\n",
    "        if ind%200 == 0:\n",
    "            print(ind)\n",
    "        word_lst = row.text\n",
    "        pos_tags = row.pos_tags\n",
    "        dependencies = row.dependencies\n",
    "        for word in aspects[ind]:\n",
    "            if len(word.split())==1:\n",
    "                word_ind = word_lst.index(word)\n",
    "                if pos_tags[dependencies[word_ind][0]-1] in ['NN','NNS']:\n",
    "                    aspects_level2[ind].append(word_lst[dependencies[word_ind][0]-1])\n",
    "    \n",
    "    return aspects_level2\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d428536a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "aspects, best_aspects = extract_aspects1(df, opinion_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "53a2d948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "aspects2 = extract_aspects2(df,aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2ab23536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(aspect2,best_aspects):\n",
    "    # prune all double words\n",
    "    pruned_aspects = []\n",
    "    for i in range(len(aspect2)):\n",
    "        temp_aspects = copy.deepcopy(aspect2[i])\n",
    "        for word in aspect2[i]:\n",
    "            if len(word.split()) == 1:\n",
    "                for word_lst in aspect2[i]:\n",
    "                    if word in word_lst.split() and len(word_lst.split())>1 and word not in best_aspects[i] and word in temp_aspects:\n",
    "                        temp_aspects.remove(word)\n",
    "        pruned_aspects.append(temp_aspects)\n",
    "    return pruned_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9692638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_aspects = prune(aspects2,best_aspects)\n",
    "actual_tags = list(train.aspect_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fae5cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_rec(aspects,labels):\n",
    "#     indiv_prec = [] # ratio of labels we got correct\n",
    "#     indiv_recall = [] # ratio of correct labels against real labels\n",
    "#     for i in range(len(aspects)):\n",
    "#         count = 0\n",
    "#         if len(aspects[i]) == 0 and len(labels[i]) == 0:\n",
    "# #             indiv_prec.append(1)\n",
    "# #             indiv_recall.append(1)\n",
    "#             pass\n",
    "#         elif len(aspects[i]) == 0 and len(labels[i]) > 0:\n",
    "#             indiv_prec.append(1)\n",
    "#             indiv_recall.append(0)\n",
    "#         elif len(aspects[i]) > 0 and len(labels[i]) == 0:\n",
    "#             indiv_prec.append(0)\n",
    "#             indiv_recall.append(1)\n",
    "#         else:\n",
    "#             for term in aspects[i]:\n",
    "#                 if term in labels[i]:\n",
    "#                     count+=1\n",
    "#             indiv_prec.append(count/len(aspects))\n",
    "#             indiv_recall.append(count/len(labels))\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    for i in range(len(aspects)):\n",
    "        if len(aspects[i]) == 0 and len(labels[i]) == 0:\n",
    "            pass\n",
    "        elif len(aspects[i]) == 0 and len(labels[i]) > 0:\n",
    "            fn += len(labels[i])\n",
    "        elif len(aspects[i]) > 0 and len(labels[i]) == 0:\n",
    "            fp += len(aspects[i])\n",
    "        else:\n",
    "            for term in aspects[i]:\n",
    "                if term in labels[i]:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            for term in labels[i]:\n",
    "                if term in aspects[i]:\n",
    "                    pass\n",
    "                else:\n",
    "                    fn += 1\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ff8a7236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.46554412223261615\n",
      "Recall:  0.39909115209836943\n"
     ]
    }
   ],
   "source": [
    "precision, recall = prec_rec(pruned_aspects,actual_tags)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e5bf8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_single(aspects):\n",
    "    aspect_lst = []\n",
    "    for lst in aspects:\n",
    "        temp_lst = []\n",
    "        for word_lst in lst:\n",
    "            if len(word_lst.split())==1:\n",
    "                temp_lst.append(word_lst)\n",
    "        aspect_lst.append(temp_lst)\n",
    "    return aspect_lst\n",
    "single_pruned_aspects = extract_single(pruned_aspects)\n",
    "single_labels = extract_single(actual_tags)\n",
    "def extract_single_double(aspects):\n",
    "    aspect_lst = []\n",
    "    for lst in aspects:\n",
    "        temp_lst = []\n",
    "        for word_lst in lst:\n",
    "            if len(word_lst.split())<=2:\n",
    "                temp_lst.append(word_lst)\n",
    "        aspect_lst.append(temp_lst)\n",
    "    return aspect_lst\n",
    "single_pruned_aspects = extract_single(pruned_aspects)\n",
    "single_labels = extract_single(actual_tags)\n",
    "double_pruned_aspects = extract_single_double(pruned_aspects)\n",
    "double_labels = extract_single_double(actual_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7bceb1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6348025186033199\n",
      "Recall:  0.3913196894848271\n"
     ]
    }
   ],
   "source": [
    "precision,recall = prec_rec(single_pruned_aspects, single_labels)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "97972dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.46554412223261615\n",
      "Recall:  0.4320023148148148\n"
     ]
    }
   ],
   "source": [
    "precision,recall = prec_rec(double_pruned_aspects, double_labels)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f8f114c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[staff]</td>\n",
       "      <td>[staff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[factor, food]</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[food, kitchen]</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[food, perks]</td>\n",
       "      <td>[food, perks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[waiters]</td>\n",
       "      <td>[orrechiete with sausage and chicken, waiters,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[taste, texture, taste]</td>\n",
       "      <td>[Bagels]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[food]</td>\n",
       "      <td>[food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[ie cheese, temperatures, ingredients]</td>\n",
       "      <td>[toast, mayonnaise, bacon, cheese, ingredients...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[]</td>\n",
       "      <td>[drinks, check]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[design]</td>\n",
       "      <td>[design, atmosphere]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[]</td>\n",
       "      <td>[cuisine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[regular neighborhood]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[]</td>\n",
       "      <td>[pizza, thin crusted pizza]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[hopping place, other night, time]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[east side]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[sheer convenience]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[interior decoration]</td>\n",
       "      <td>[interior decoration, chefs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[seats]</td>\n",
       "      <td>[seats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[]</td>\n",
       "      <td>[seltzer with lime]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[people, whole experience]</td>\n",
       "      <td>[pickles, selection of meats and seafoods]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[family style]</td>\n",
       "      <td>[dishes, eat family style]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[vibe, owner, service]</td>\n",
       "      <td>[vibe, owner, service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[concept]</td>\n",
       "      <td>[delivery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[food, atmosphere, service, downtown neighborh...</td>\n",
       "      <td>[food, atmosphere, service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[food, prices, food]</td>\n",
       "      <td>[food, prices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[other steakhouse]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[little place, interior, interior decor, city,...</td>\n",
       "      <td>[interior decor, prices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[wine]</td>\n",
       "      <td>[wine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[price, service]</td>\n",
       "      <td>[price, service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[quantity]</td>\n",
       "      <td>[quantity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[times]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[original store]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[second floor, floor walk, serious sushi, sush...</td>\n",
       "      <td>[sushi, sushi bar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[restaurant]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[rice]</td>\n",
       "      <td>[fried rice]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pred  \\\n",
       "0                                             [staff]   \n",
       "1                                      [factor, food]   \n",
       "2                                     [food, kitchen]   \n",
       "3                                                  []   \n",
       "4                                                  []   \n",
       "5                                       [food, perks]   \n",
       "6                                                  []   \n",
       "7                                           [waiters]   \n",
       "8                             [taste, texture, taste]   \n",
       "9                                              [food]   \n",
       "10             [ie cheese, temperatures, ingredients]   \n",
       "11                                                 []   \n",
       "12                                           [design]   \n",
       "13                                                 []   \n",
       "14                             [regular neighborhood]   \n",
       "15                                                 []   \n",
       "16                 [hopping place, other night, time]   \n",
       "17                                                 []   \n",
       "18                                        [east side]   \n",
       "19                                [sheer convenience]   \n",
       "20                                                 []   \n",
       "21                                                 []   \n",
       "22                                                 []   \n",
       "23                                                 []   \n",
       "24                                                 []   \n",
       "25                              [interior decoration]   \n",
       "26                                            [seats]   \n",
       "27                                                 []   \n",
       "28                                                 []   \n",
       "29                                                 []   \n",
       "30                         [people, whole experience]   \n",
       "31                                     [family style]   \n",
       "32                             [vibe, owner, service]   \n",
       "33                                                 []   \n",
       "34                                          [concept]   \n",
       "35  [food, atmosphere, service, downtown neighborh...   \n",
       "36                               [food, prices, food]   \n",
       "37                                                 []   \n",
       "38                                 [other steakhouse]   \n",
       "39                                                 []   \n",
       "40  [little place, interior, interior decor, city,...   \n",
       "41                                                 []   \n",
       "42                                             [wine]   \n",
       "43                                   [price, service]   \n",
       "44                                         [quantity]   \n",
       "45                                            [times]   \n",
       "46                                   [original store]   \n",
       "47  [second floor, floor walk, serious sushi, sush...   \n",
       "48                                       [restaurant]   \n",
       "49                                             [rice]   \n",
       "\n",
       "                                                 true  \n",
       "0                                             [staff]  \n",
       "1                                              [food]  \n",
       "2                               [food, kitchen, menu]  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "5                                       [food, perks]  \n",
       "6                                                  []  \n",
       "7   [orrechiete with sausage and chicken, waiters,...  \n",
       "8                                            [Bagels]  \n",
       "9                                              [food]  \n",
       "10  [toast, mayonnaise, bacon, cheese, ingredients...  \n",
       "11                                    [drinks, check]  \n",
       "12                               [design, atmosphere]  \n",
       "13                                          [cuisine]  \n",
       "14                                                 []  \n",
       "15                        [pizza, thin crusted pizza]  \n",
       "16                                                 []  \n",
       "17                                                 []  \n",
       "18                                                 []  \n",
       "19                                                 []  \n",
       "20                                                 []  \n",
       "21                                                 []  \n",
       "22                                                 []  \n",
       "23                                                 []  \n",
       "24                                                 []  \n",
       "25                       [interior decoration, chefs]  \n",
       "26                                            [seats]  \n",
       "27                                [seltzer with lime]  \n",
       "28                                                 []  \n",
       "29                                                 []  \n",
       "30         [pickles, selection of meats and seafoods]  \n",
       "31                         [dishes, eat family style]  \n",
       "32                             [vibe, owner, service]  \n",
       "33                                                 []  \n",
       "34                                         [delivery]  \n",
       "35                        [food, atmosphere, service]  \n",
       "36                                     [food, prices]  \n",
       "37                                                 []  \n",
       "38                                                 []  \n",
       "39                                                 []  \n",
       "40                           [interior decor, prices]  \n",
       "41                                                 []  \n",
       "42                                             [wine]  \n",
       "43                                   [price, service]  \n",
       "44                                         [quantity]  \n",
       "45                                                 []  \n",
       "46                                                 []  \n",
       "47                                 [sushi, sushi bar]  \n",
       "48                                                 []  \n",
       "49                                       [fried rice]  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_labels = pd.DataFrame()\n",
    "compare_labels['pred'] = pruned_aspects\n",
    "compare_labels['true'] = actual_tags\n",
    "compare_labels[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16eb4503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food is uniformly exceptional , with a very capable kitchen which will proudly whip up whatever you feel like eating , whether it 's on the menu or not .\n",
      "['The', 'food', 'is', 'uniformly', 'exceptional', ',', 'with', 'a', 'very', 'capable', 'kitchen', 'which', 'will', 'proudly', 'whip', 'up', 'whatever', 'you', 'feel', 'like', 'eating', ',', 'whether', 'it', \"'s\", 'on', 'the', 'menu', 'or', 'not', '.']\n",
      "['DT', 'NN', 'VBZ', 'RB', 'JJ', ',', 'IN', 'DT', 'RB', 'JJ', 'NN', 'WDT', 'MD', 'RB', 'VB', 'RP', 'WDT', 'PRP', 'VBP', 'IN', 'VBG', ',', 'IN', 'PRP', 'VBZ', 'IN', 'DT', 'NN', 'CC', 'RB', '.']\n",
      "[(2, 'det'), (5, 'nsubj'), (5, 'cop'), (5, 'advmod'), (0, 'root'), (5, 'punct'), (11, 'case'), (11, 'det'), (10, 'advmod'), (11, 'amod'), (5, 'obl'), (15, 'nsubj'), (15, 'aux'), (15, 'advmod'), (11, 'acl:relcl'), (15, 'compound:prt'), (15, 'obj'), (19, 'nsubj'), (17, 'acl:relcl'), (21, 'mark'), (19, 'advcl'), (28, 'punct'), (28, 'mark'), (28, 'nsubj'), (28, 'cop'), (28, 'case'), (28, 'det'), (19, 'advcl'), (30, 'cc'), (28, 'conj'), (5, 'punct')]\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[2].text_full)\n",
    "print(df.loc[2].text)\n",
    "print(df.loc[2].pos_tags)\n",
    "print(df.loc[2].dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc19e7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fried', 'VBN'), ('rice', 'NN')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.pos_tag(['fried','rice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c40d2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_pred = [word for sublist in single_pruned_aspects for word in sublist]\n",
    "flat_test = [word for sublist in actual_tags for word in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e75e6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food          226\n",
       "service       145\n",
       "place          86\n",
       "staff          40\n",
       "prices         38\n",
       "restaurant     33\n",
       "atmosphere     29\n",
       "Service        22\n",
       "meal           21\n",
       "experience     20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(np.array(flat_pred)).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "321c61b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food          357\n",
       "service       206\n",
       "place          64\n",
       "prices         60\n",
       "menu           57\n",
       "staff          56\n",
       "dinner         55\n",
       "atmosphere     49\n",
       "pizza          43\n",
       "table          41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(np.array(flat_test)).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8349473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_full                        The fried rice is amazing here .\n",
       "text                     [The, fried, rice, is, amazing, here, .]\n",
       "pos_tags                            [DT, VBN, NN, VBZ, JJ, RB, .]\n",
       "dependencies    [(3, det), (3, amod), (5, nsubj), (5, cop), (0...\n",
       "Name: 49, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56e5b3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egg noodles in the beef broth with shrimp dumplings and slices of BBQ roast pork\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 2786,\n",
       " 5: 26,\n",
       " 3: 178,\n",
       " 2: 622,\n",
       " 4: 60,\n",
       " 6: 8,\n",
       " 13: 2,\n",
       " 7: 2,\n",
       " 10: 2,\n",
       " 8: 1,\n",
       " 9: 4,\n",
       " 19: 1,\n",
       " 15: 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_dic = {}\n",
    "for lst in actual_tags:\n",
    "    for aspects in lst:\n",
    "        leng = len(aspects.split())\n",
    "        if leng not in count_dic.keys():\n",
    "            count_dic[leng] = 1\n",
    "        else:\n",
    "            count_dic[leng] += 1\n",
    "        if leng == 15:\n",
    "            print( aspects)\n",
    "count_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "251aa878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_dic = {}\n",
    "for lst in actual_tags:\n",
    "    len_lst = len(lst)\n",
    "    if len_lst not in len_dic.keys():\n",
    "        len_dic[len_lst] = 1\n",
    "    else:\n",
    "        len_dic[len_lst] +=1\n",
    "len_dic # total = 3041\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ede13",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2ce77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def baseline_model(data):\n",
    "    aspect_lst = []\n",
    "    for i in data.text:\n",
    "        temp_wordlst = [word for word in i if word not in string.punctuation]\n",
    "        temp_aspects =[]\n",
    "        num_aspects = np.random.choice(np.arange(0, 10), p=[1020/3041, 1023/3041, 572/3041, 269/3041, 104/3041, 29/3041,15/3041,5/3041,3/3041,1/3041])\n",
    "        for j in range(num_aspects):\n",
    "            len_aspects = np.random.choice(np.arange(1,9), p=[2786/3683,622/3683,178/3683,60/3683,26/3683,8/3683,2/3683,1/3683])\n",
    "            if len_aspects>=len(temp_wordlst):\n",
    "                temp_aspects.append(' '.join(temp_wordlst))\n",
    "            else:\n",
    "                max_ind = len(temp_wordlst)-len_aspects\n",
    "                if max_ind-1 == 0:\n",
    "                    start_ind = 0\n",
    "                else:\n",
    "                    start_ind = np.random.randint(0,max_ind-1)\n",
    "                aspect_joined = \" \".join(temp_wordlst[start_ind:start_ind+len_aspects])\n",
    "                temp_aspects.append(aspect_joined)\n",
    "                temp_wordlst = temp_wordlst[:start_ind] + temp_wordlst[start_ind+len_aspects:]\n",
    "        aspect_lst.append(temp_aspects)\n",
    "    return aspect_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fed54611",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_extraction = baseline_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a8de1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.05486628067273228\n",
      "Recall:  0.05385656292286874\n"
     ]
    }
   ],
   "source": [
    "precision, recall = prec_rec(baseline_extraction,actual_tags)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1cfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
